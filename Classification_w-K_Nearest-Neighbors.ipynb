{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc0cf200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb25856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56b81f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c51cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afb9dda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3a47bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('breast-cancer-wisconsin.data')\n",
    "df.replace('?', -99999, inplace=True)\n",
    "df.drop(columns='id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff971aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df.drop(columns='class',axis=11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d82456ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9785714285714285\n"
     ]
    }
   ],
   "source": [
    "#x = np.array(df.drop(['class']),1)\n",
    "x = np.array(df.drop(columns='class',axis=11))\n",
    "y = np.array(df['class'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "accuracy = clf.score(x_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01de8970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2]\n"
     ]
    }
   ],
   "source": [
    "example_measures = np.array([[4,2,1,1,1,2,3,2,1], [4,2,1,2,2,2,3,2,1]])\n",
    "\n",
    "example_measures = example_measures.reshape(len(example_measures),-1)\n",
    "\n",
    "\n",
    "prediction = clf.predict(example_measures)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b779740",
   "metadata": {},
   "source": [
    "# EUCLIDEAN DISTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1eb7593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbf8fc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "plot1=[1,3]\n",
    "plot2=[2,5]\n",
    "\n",
    "eclidean_distance = sqrt((plot1[0] - plot2[0])**2 + (plot1[1] - plot2[1])**2)\n",
    "\n",
    "print(eclidean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50334a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9a80ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a38a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import warnings\n",
    "from math import sqrt\n",
    "from collections import Counter\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "    if len(data) >= k:\n",
    "        warnings.warn('K is set to a value less than total voting groups!')\n",
    "        \n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict))\n",
    "            distances.append([euclidean_distance,group])\n",
    "\n",
    "    votes = [i[1] for i in sorted(distances)[:k]]\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    return vote_result\n",
    "\n",
    "dataset = {'k':[[1,2],[2,3],[3,1]], 'r':[[6,5],[7,7],[8,6]]}\n",
    "new_features = [5,7]\n",
    "\n",
    "[[plt.scatter(ii[0],ii[1],s=100,color=i) for ii in dataset[i]] for i in dataset]\n",
    "        \n",
    "plt.scatter(new_features[0], new_features[1], s=100)\n",
    "\n",
    "result = k_nearest_neighbors(dataset, new_features)\n",
    "plt.scatter(new_features[0], new_features[1], s=100, color = result)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040535e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c966f54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('r', 3)]\n",
      "r\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import warnings\n",
    "from math import sqrt\n",
    "from collections import Counter\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "    if len(data) >=k:\n",
    "        warnings.warn('K is set to a value less than total voting groups!')   \n",
    "    \n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict))\n",
    "            distances.append([euclidean_distance,group])\n",
    "    \n",
    "    votes = [i[1] for i in sorted(distances)[:k]]\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    print(Counter(votes).most_common(1))\n",
    "    \n",
    "    return vote_result\n",
    "    \n",
    "dataset = {'k':[[1,2],[2,3],[3,1]], 'r':[[6,5],[7,7],[8,6]]}\n",
    "new_features = [5,7]\n",
    "\n",
    "result = k_nearest_neighbors(dataset, new_features, k=3)\n",
    "print(result)\n",
    "\n",
    "[[plt.scatter(ii[0], ii[1], s=100, color=i) for ii in dataset[i]] for i in dataset]\n",
    "plt.scatter(new_features[0],new_features[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d36cccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "n = [[1, 2, 3], [4, 5, 6, 7, 8, 9]]\n",
    "\n",
    "def flatten(lists):\n",
    "    results = []\n",
    "    for numbers in range(len(lists)):\n",
    "        for i in range(len(lists[numbers])):\n",
    "            results.append(lists[numbers][i])\n",
    "    return results\n",
    "\n",
    "resul = flatten(n)\n",
    "print(resul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83990424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import warnings\n",
    "from math import sqrt\n",
    "from collections import Counter\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "    if len(data) >= k:\n",
    "        warnings.warn('K is set to a value less than total voting groups!')\n",
    "        \n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict))\n",
    "            distances.append([euclidean_distance,group])\n",
    "\n",
    "    votes = [i[1] for i in sorted(distances)[:k]]\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    return vote_result\n",
    "\n",
    "dataset = {'k':[[1,2],[2,3],[3,1]], 'r':[[6,5],[7,7],[8,6]]}\n",
    "new_features = [5,7]\n",
    "\n",
    "[[plt.scatter(ii[0],ii[1],s=100,color=i) for ii in dataset[i]] for i in dataset]\n",
    "        \n",
    "plt.scatter(new_features[0], new_features[1], s=100)\n",
    "\n",
    "result = k_nearest_neighbors(dataset, new_features)\n",
    "plt.scatter(new_features[0], new_features[1], s=100, color = result)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1829db7",
   "metadata": {},
   "source": [
    "# Applying our K Nearest Neighbors Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7223eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from math import sqrt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "    if len(data) >= k:\n",
    "        warnings.warn('K is set to a value less than total voting groups!')\n",
    "        \n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict))\n",
    "            distances.append([euclidean_distance,group])\n",
    "\n",
    "    votes = [i[1] for i in sorted(distances)[:k]]\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    \n",
    "    return vote_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602a1514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   clump_thickness  unif_cell_size  unif_cell_shape  marg_adhesion  \\\n",
      "0                5               1                1              1   \n",
      "1                5               4                4              5   \n",
      "2                3               1                1              1   \n",
      "3                6               8                8              1   \n",
      "4                4               1                1              3   \n",
      "\n",
      "   single_epith_cell_size bare_nuclei  bland_chrom   norm_nucleoli  mitoses  \\\n",
      "0                       2           1            3               1        1   \n",
      "1                       7          10            3               2        1   \n",
      "2                       2           2            3               1        1   \n",
      "3                       3           4            3               7        1   \n",
      "4                       2           1            3               1        1   \n",
      "\n",
      "   class  \n",
      "0      2  \n",
      "1      2  \n",
      "2      2  \n",
      "3      2  \n",
      "4      2  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/58/j_8hz7px0l30bjvcrr05krz00000gn/T/ipykernel_12552/48961863.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop(['id'], 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"breast-cancer-wisconsin.data.txt\")\n",
    "df.replace('?',-99999, inplace=True)\n",
    "df.drop(['id'], 1, inplace=True)\n",
    "\n",
    "print(df.head())\n",
    "#full_data = df.astype(float).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05f2ff5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0], [5.0, 4.0, 4.0, 5.0, 7.0, 10.0, 3.0, 2.0, 1.0, 2.0], [3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 2.0], [6.0, 8.0, 8.0, 1.0, 3.0, 4.0, 3.0, 7.0, 1.0, 2.0], [4.0, 1.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0]]\n",
      "#################### The Shuffle\n",
      "[[4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0], [3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0], [10.0, 4.0, 3.0, 10.0, 4.0, 10.0, 10.0, 1.0, 1.0, 4.0], [10.0, 4.0, 2.0, 1.0, 3.0, 2.0, 4.0, 3.0, 10.0, 4.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0]]\n"
     ]
    }
   ],
   "source": [
    "full_data = df.astype(float).values.tolist()\n",
    "print(full_data[:5])\n",
    "random.shuffle(full_data)\n",
    "print(20*'#' +' The Shuffle')\n",
    "print(full_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd150bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9784172661870504\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "train_set = {2:[], 4:[]}\n",
    "test_set = {2:[], 4:[]}\n",
    "train_data = full_data[:-int(test_size*len(full_data))]\n",
    "test_data = full_data[-int(test_size*len(full_data)):]\n",
    "\n",
    "for i in train_data:\n",
    "    train_set[i[-1]].append(i[:-1])\n",
    "    \n",
    "for i in test_data:\n",
    "    test_set[i[-1]].append(i[:-1])\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for group in test_set:\n",
    "    for data in test_set[group]:\n",
    "        vote = k_nearest_neighbors(train_set, data, k=5)\n",
    "        if group == vote:\n",
    "            correct +=1\n",
    "        total +=1\n",
    "print('Accuracy: ', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12ee9e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/58/j_8hz7px0l30bjvcrr05krz00000gn/T/ipykernel_12552/4155704794.py:28: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop(['id'], 1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.8\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.6\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 0.8\n",
      "2 0.6\n",
      "2 0.6\n",
      "4 1.0\n",
      "4 0.6\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "2 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.6\n",
      "4 0.6\n",
      "4 1.0\n",
      "4 0.8\n",
      "2 0.6\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "2 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "Accuracy:  0.9640287769784173\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from math import sqrt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "    if len(data) >= k:\n",
    "        warnings.warn('K is set to a value less than total voting groups!')\n",
    "        \n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict))\n",
    "            distances.append([euclidean_distance,group])\n",
    "\n",
    "    votes = [i[1] for i in sorted(distances)[:k]]\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    confidence = Counter(votes).most_common(1)[0][1] / k\n",
    "    \n",
    "    print(vote_result, confidence)\n",
    "    \n",
    "    return vote_result, confidence\n",
    "\n",
    "df = pd.read_csv(\"breast-cancer-wisconsin.data.txt\")\n",
    "df.replace('?',-99999, inplace=True)\n",
    "df.drop(['id'], 1, inplace=True)\n",
    "full_data = df.astype(float).values.tolist()\n",
    "random.shuffle(full_data)\n",
    "\n",
    "test_size = 0.2\n",
    "train_set = {2:[], 4:[]}\n",
    "test_set = {2:[], 4:[]}\n",
    "train_data = full_data[:-int(test_size*len(full_data))]\n",
    "test_data = full_data[-int(test_size*len(full_data)):]\n",
    "\n",
    "for i in train_data:\n",
    "    train_set[i[-1]].append(i[:-1])\n",
    "    \n",
    "for i in test_data:\n",
    "    test_set[i[-1]].append(i[:-1])\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for group in test_set:\n",
    "    for data in test_set[group]:\n",
    "        vote, confidence = k_nearest_neighbors(train_set, data, k=5)\n",
    "        if group == vote:\n",
    "            correct +=1\n",
    "        total +=1\n",
    "print('Accuracy: ', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0186deb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.8\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.6\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 0.8\n",
      "2 0.6\n",
      "0.6\n",
      "2 0.6\n",
      "0.6\n",
      "4 1.0\n",
      "4 0.6\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "2 0.8\n",
      "0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.6\n",
      "4 0.6\n",
      "4 1.0\n",
      "4 0.8\n",
      "2 0.6\n",
      "0.6\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "2 0.8\n",
      "0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "Accuracy:  0.9640287769784173\n"
     ]
    }
   ],
   "source": [
    "for group in test_set:\n",
    "    for data in test_set[group]:\n",
    "        vote, confidence = k_nearest_neighbors(train_set, data, k=5)\n",
    "        if group == vote:\n",
    "            correct +=1\n",
    "        else:\n",
    "            print(confidence)\n",
    "        total +=1\n",
    "print('Accuracy: ', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "777db278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/58/j_8hz7px0l30bjvcrr05krz00000gn/T/ipykernel_12552/2227803735.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop(['id'], 1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1.0\n",
      "2 0.6\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.6\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "4 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.8\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "4 0.6\n",
      "2 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 0.6\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 0.6\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 0.8\n",
      "2 0.6\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "2 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 0.6\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "2 0.6\n",
      "4 1.0\n",
      "4 1.0\n",
      "2 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "2 1.0\n",
      "Accuracy:  0.9496402877697842\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "4 0.8\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "2 0.6\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.6\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.6\n",
      "4 0.6\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "2 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.6\n",
      "2 0.8\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "Accuracy:  0.9712230215827338\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.8\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.6\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "4 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "4 1.0\n",
      "2 0.6\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.6\n",
      "4 1.0\n",
      "2 0.6\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "2 0.6\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.6\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "Accuracy:  0.9712230215827338\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.6\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.6\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.6\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.6\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.6\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "Accuracy:  1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "4 0.8\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.8\n",
      "4 0.8\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "4 0.6\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.6\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "2 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "2 0.6\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "2 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.6\n",
      "4 1.0\n",
      "2 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "Accuracy:  0.9496402877697842\n",
      "0.9683453237410072\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "\n",
    "for i in range(5):\n",
    "    df = pd.read_csv(\"breast-cancer-wisconsin.data.txt\")\n",
    "    df.replace('?',-99999, inplace=True)\n",
    "    df.drop(['id'], 1, inplace=True)\n",
    "    full_data = df.astype(float).values.tolist()\n",
    "    random.shuffle(full_data)\n",
    "\n",
    "    test_size = 0.2\n",
    "    train_set = {2:[], 4:[]}\n",
    "    test_set = {2:[], 4:[]}\n",
    "    train_data = full_data[:-int(test_size*len(full_data))]\n",
    "    test_data = full_data[-int(test_size*len(full_data)):]\n",
    "\n",
    "    for i in train_data:\n",
    "        train_set[i[-1]].append(i[:-1])\n",
    "\n",
    "    for i in test_data:\n",
    "        test_set[i[-1]].append(i[:-1])\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for group in test_set:\n",
    "        for data in test_set[group]:\n",
    "            vote, confidence = k_nearest_neighbors(train_set, data, k=5)\n",
    "            if group == vote:\n",
    "                correct +=1\n",
    "            total +=1\n",
    "    print('Accuracy: ', correct/total)\n",
    "    accuracies.append(correct/total)\n",
    "\n",
    "print(sum(accuracies)/len(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe4b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing, neighbors, svm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67340e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6714285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/58/j_8hz7px0l30bjvcrr05krz00000gn/T/ipykernel_20844/2144483614.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop(['id'], 1, inplace=True)\n",
      "/var/folders/58/j_8hz7px0l30bjvcrr05krz00000gn/T/ipykernel_20844/2144483614.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  x = np.array(df.drop(['class'], 1))\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('breast-cancer-wisconsin.data.txt')\n",
    "df.replace('?', -99999, inplace=True)\n",
    "df.drop(['id'], 1, inplace=True)\n",
    "\n",
    "x = np.array(df.drop(['class'], 1))\n",
    "y = np.array(df['class'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "accuracy = clf.score(x_test, y_test)\n",
    "print(accuracy)\n",
    "\n",
    "#example_measures = np.array([[4,2,1,1,1,2,3,2,1],[4,2,1,2,2,2,3,2,1]])\n",
    "\n",
    "#example_measures = example_measures.reshape(len(example_measures), -1)\n",
    "\n",
    "#prediction = clf.predict(example_measures)\n",
    "#print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6261a455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195eb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
